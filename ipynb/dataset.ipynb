{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FJ9m2enVQwsT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZNPP17We6Jh"
      },
      "source": [
        "# Dependance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JETr6jHGfi9D"
      },
      "source": [
        "class Scanner:\n",
        "  import numpy\n",
        "  \n",
        "  def __init__(self, type):\n",
        "    self.type = type\n",
        "    self.tokens = None;\n",
        "\n",
        "  def scan(self, content):\n",
        "    return {\n",
        "        'csv': lambda x: self.scanCSV(x)\n",
        "    }[self.type](content)\n",
        "    \n",
        "  def scanCSV(self, content):\n",
        "    lines = content.split()\n",
        "    items = []\n",
        "\n",
        "    for line in lines:  \n",
        "      items.append( line.split(',') )\n",
        "\n",
        "    tokens = numpy.array(items)\n",
        "    return tokens\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e019Nn2PhZ9l"
      },
      "source": [
        "class Parser:\n",
        "  import numpy\n",
        "  \n",
        "  def __init__(self, methods):\n",
        "    self.methods = methods\n",
        "  \n",
        "  def parse(self, slices):\n",
        "    methods = self.methods\n",
        "    items = []\n",
        "\n",
        "    for i in range( len(methods) ):\n",
        "      method = methods[i]\n",
        "      matrix = numpy.array(slices[i]).transpose()\n",
        "\n",
        "      for row in matrix:\n",
        "        newrow = list( map(lambda x: method(x), row) )\n",
        "        items.append( newrow )\n",
        "\n",
        "    datas = numpy.array(items).transpose()\n",
        "    return datas"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoJtSJZvng-F"
      },
      "source": [
        "def source(path, source):\n",
        "  import os\n",
        "\n",
        "  if not os.path.isfile(path):\n",
        "    !mkdir data\n",
        "    !wget $source --force-directories -O $path "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37jFQD6rnnoD"
      },
      "source": [
        "def write(path, content):\n",
        "  fp = open(path, 'wb')\n",
        "  fp.write(content)\n",
        "  fp.close()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lBJzZ9_olli"
      },
      "source": [
        "def unpickle(path):\n",
        "  import pickle\n",
        "  with open(path, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "  return dict"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7C9MrDGdqAQ"
      },
      "source": [
        "# Iris\n",
        "- feature: 4\n",
        "- target: 1\n",
        "- types: Setosa, Versicolour, Virginica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrZmqI9seHyW"
      },
      "source": [
        "class Iris:\n",
        "  def __init__(self, content = None):\n",
        "    if content is None: content = self.__source('data/iris.data')\n",
        "\n",
        "    tokens = Scanner('csv').scan(content);\n",
        "\n",
        "    features = Parser([\n",
        "      lambda x: float(x)\n",
        "    ]).parse([\n",
        "      tokens[:, 0:-1]\n",
        "    ])\n",
        "\n",
        "    targets = Parser([\n",
        "      lambda x: ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'].index(x)\n",
        "    ]).parse([\n",
        "      tokens[:, -1:]\n",
        "    ])\n",
        "\n",
        "    classes = ['setosa', 'versicolor', 'virginica']\n",
        "\n",
        "    self.features = features\n",
        "    self.targets = targets\n",
        "    self.classes = classes\n",
        "\n",
        "  def __source(self, path):\n",
        "    SOURCE = 'https://raw.githubusercontent.com/s10459020/Database/main/iris/iris.data'\n",
        "\n",
        "    if not os.path.isfile(path):\n",
        "      !mkdir data\n",
        "      !wget -O $path $SOURCE\n",
        "    return open(path).read()"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYw01084bmHU"
      },
      "source": [
        "iris = Iris()\n",
        "print(iris.classes)\n",
        "print(iris.features[:5])\n",
        "print(iris.targets[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lthm3hCkdr0R"
      },
      "source": [
        "# Waveform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB61Fyptds_x"
      },
      "source": [
        "class Waveform:\n",
        "  def __init__(self, content = None):\n",
        "    if content is None: content = self.__source('data/waveform.data')\n",
        "\n",
        "    tokens = Scanner('csv').scan(content);\n",
        "\n",
        "    features = Parser([\n",
        "      lambda x: float(x)\n",
        "    ]).parse([\n",
        "      tokens[:, 0:-1]\n",
        "    ])\n",
        "\n",
        "    targets = Parser([\n",
        "      lambda x: ['0', '1', '2'].index(x)\n",
        "    ]).parse([\n",
        "      tokens[:, -1:]\n",
        "    ])\n",
        "\n",
        "    classes = ['waveform 1', 'waveform 2', 'waveform 3']\n",
        "\n",
        "    self.features = features\n",
        "    self.targets = targets\n",
        "    self.classes = classes\n",
        "\n",
        "  def __source(self, path):\n",
        "    SOURCE = 'https://raw.githubusercontent.com/s10459020/Database/main/waveform/waveform.data'\n",
        "\n",
        "    if not os.path.isfile(path):\n",
        "      !mkdir data\n",
        "      !wget $SOURCE --force-directories -O $path \n",
        "    return open(path).read()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqO26bjBb-cN"
      },
      "source": [
        "waveform = Waveform()\n",
        "print(waveform.classes)\n",
        "print(waveform.features[:5])\n",
        "print(waveform.targets[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nRn9CHvdvoJ"
      },
      "source": [
        "# WDBC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzK5R-I2dxe0"
      },
      "source": [
        "class Wdbc:\n",
        "  def __init__(self, content = None):\n",
        "    if content is None: content = self.__source('data/wdbc.data')\n",
        "\n",
        "    tokens = Scanner('csv').scan(content);\n",
        "\n",
        "    features = Parser([\n",
        "      lambda x: float(x)\n",
        "    ]).parse([\n",
        "      tokens[:, 2:12]\n",
        "    ])\n",
        "\n",
        "    targets = Parser([\n",
        "      lambda x: ['M', 'B'].index(x)\n",
        "    ]).parse([\n",
        "      tokens[:, 1:2]\n",
        "    ])\n",
        "\n",
        "    classes = ['malignant', 'benign']\n",
        "\n",
        "    self.features = features\n",
        "    self.targets = targets\n",
        "    self.classes = classes\n",
        "\n",
        "  def __source(self, path):\n",
        "    SOURCE = 'https://raw.githubusercontent.com/s10459020/Database/main/wdbc/wdbc.data'\n",
        "\n",
        "    if not os.path.isfile(path):\n",
        "      !mkdir data\n",
        "      !wget $SOURCE --force-directories -O $path \n",
        "    return open(path).read()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMS9dMA5jI1o"
      },
      "source": [
        "wdbc = Wdbc()\n",
        "print(wdbc.classes)\n",
        "print(wdbc.features[:5])\n",
        "print(wdbc.targets[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JKFNVFNQzI3"
      },
      "source": [
        "# CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1oqOwFJQ0NC"
      },
      "source": [
        "class Cifar10:\n",
        "  def __init__(self, content = None):\n",
        "    import numpy\n",
        "    FILEPATH = 'data/cifar10.pickle'\n",
        "    TEMP = 'data/cifar10_batch'\n",
        "\n",
        "    if content: \n",
        "      write(FILEPATH, content)\n",
        "      cifar = unpickle(FILEPATH)\n",
        "      self.data = cifar[b'data']\n",
        "      self.label = cifar[b'labels']\n",
        "\n",
        "    else: \n",
        "      dataArray = []\n",
        "      labelArray = []\n",
        "      for i in range(1, 6):   \n",
        "        source( TEMP + str(i), 'https://raw.githubusercontent.com/s10459020/Database/main/cifar-10/data_batch_' + str(i) )\n",
        "        cifar_batch = unpickle( TEMP + str(i) )\n",
        "\n",
        "        dataArray = numpy.concatenate( (dataArray, cifar_batch[b'data']) ) if len(dataArray) > 0 else cifar_batch[b'data']\n",
        "        labelArray = labelArray + cifar_batch[b'labels'] if len(labelArray) > 0 else cifar_batch[b'labels']\n",
        "\n",
        "      self.data = dataArray\n",
        "      self.label = labelArray"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxrEPFO-b29C"
      },
      "source": [
        "cifar10 = Cifar10()\n",
        "print(f'data({ len(cifar10.data) }): { cifar10.data }')\n",
        "print(f'label({ len(cifar10.label) }): { cifar10.label }')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}